{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guswns3396/PSYC-221-Project/blob/main/Segment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Q5GpsLKubH3y"
      },
      "id": "Q5GpsLKubH3y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/PSYC221\""
      ],
      "metadata": {
        "id": "O2yd05XjN0_1"
      },
      "id": "O2yd05XjN0_1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "xw9eZqktN53Q"
      },
      "id": "xw9eZqktN53Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install & Import Dependencies"
      ],
      "metadata": {
        "id": "hpRHy7MQAH0q"
      },
      "id": "hpRHy7MQAH0q"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "id": "ASJXEkc4Xo5e"
      },
      "id": "ASJXEkc4Xo5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nibabel as nib\n",
        "\n",
        "import monai\n",
        "import monai.transforms as mt\n",
        "from monai.data import PersistentDataset, Dataset, DataLoader\n",
        "from monai.apps import CrossValidation\n",
        "\n",
        "from monai.utils import set_determinism\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "cgz1UzGxAAZp"
      },
      "id": "cgz1UzGxAAZp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.cpu_count()"
      ],
      "metadata": {
        "id": "jpWj_qLSi6Mc"
      },
      "id": "jpWj_qLSi6Mc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
        "available_gpus"
      ],
      "metadata": {
        "id": "GOzScJBwiNCA"
      },
      "id": "GOzScJBwiNCA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_determinism(seed=0)"
      ],
      "metadata": {
        "id": "fhC342sKE-Ee"
      },
      "id": "fhC342sKE-Ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Data"
      ],
      "metadata": {
        "id": "GN3BAAIBGjT7"
      },
      "id": "GN3BAAIBGjT7"
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_TYPES = {\n",
        "  'bravo': 0,\n",
        "  'flair': 1,\n",
        "  't1_gd': 2,\n",
        "  't1_pre': 3\n",
        "}"
      ],
      "metadata": {
        "id": "SEYlR-y-hEyu"
      },
      "id": "SEYlR-y-hEyu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_dicts(path):\n",
        "  data = [\n",
        "    {\n",
        "      'img': [os.path.join(subj, img_type + '.nii.gz') for img_type in IMG_TYPES],\n",
        "      'seg': os.path.join(subj, 'seg.nii.gz')\n",
        "    }\n",
        "    for subj in glob(os.path.join(path, 'Mets_*'))\n",
        "  ]\n",
        "  return data"
      ],
      "metadata": {
        "id": "U76SpNPt0OZe"
      },
      "id": "U76SpNPt0OZe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_meta(metatensor):\n",
        "  \"\"\"\n",
        "  fix meta information of metatensor after stacking\n",
        "  \"\"\"\n",
        "  # fix img meta\n",
        "  a = [metatensor.ndim, *metatensor.shape[1:], metatensor.shape[0]]\n",
        "  for i, val in enumerate(a):\n",
        "    metatensor.meta['dim'][i] = val\n",
        "  metatensor.meta['original_channel_dim'] = -1\n",
        "  return metatensor"
      ],
      "metadata": {
        "id": "2xi1bmdx4HVf"
      },
      "id": "2xi1bmdx4HVf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_data(metatensor):\n",
        "  print(metatensor.shape)\n",
        "  print(metatensor.meta)\n",
        "  return metatensor"
      ],
      "metadata": {
        "id": "nSojSNFB-z4i"
      },
      "id": "nSojSNFB-z4i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a29a7bbd",
      "metadata": {
        "id": "a29a7bbd"
      },
      "outputs": [],
      "source": [
        "path_train = 'brainmetshare-3/train'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dicts = get_data_dicts(path_train)"
      ],
      "metadata": {
        "id": "ZjygWPYGz4h-"
      },
      "id": "ZjygWPYGz4h-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "jQNIxi3nCruN"
      },
      "id": "jQNIxi3nCruN"
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = Dataset(\n",
        "  data_dicts,\n",
        "  transform=mt.Compose([\n",
        "    # load images\n",
        "    mt.LoadImageD(['img', 'seg']),\n",
        "  ])\n",
        ")"
      ],
      "metadata": {
        "id": "Z7HRPP-Y4I_-"
      },
      "id": "Z7HRPP-Y4I_-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load & Pre-Process Data"
      ],
      "metadata": {
        "id": "MMCIztiZ592a"
      },
      "id": "MMCIztiZ592a"
    },
    {
      "cell_type": "code",
      "source": [
        "KEYS = ('img', 'seg')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "xform_train = mt.Compose([\n",
        "  # load images\n",
        "  mt.LoadImageD(KEYS),\n",
        "  # make channel the first dimension / add channel dimension if necessary\n",
        "  mt.EnsureChannelFirstD(KEYS),\n",
        "  # fix meta\n",
        "  mt.LambdaD(KEYS, fix_meta),\n",
        "  # print data to ensure fix\n",
        "  # mt.LambdaD(KEYS, print_data),\n",
        "  # make sure tensor type\n",
        "  mt.EnsureTypeD(keys=KEYS),\n",
        "  # make sure all have same orientation (axcode)\n",
        "  mt.Orientationd(keys=KEYS, axcodes=\"RAS\"),\n",
        "  mt.Spacingd(\n",
        "      keys=KEYS,\n",
        "      pixdim=(1.0, 1.0, 1.0),\n",
        "      mode=(\"bilinear\", \"nearest\"),\n",
        "  ),\n",
        "  # augment data to be invariant to orientation\n",
        "  mt.RandFlipd(keys=KEYS, prob=0.5, spatial_axis=0),\n",
        "  mt.RandFlipd(keys=KEYS, prob=0.5, spatial_axis=1),\n",
        "  mt.RandFlipd(keys=KEYS, prob=0.5, spatial_axis=2),\n",
        "  # normalize intensity\n",
        "  mt.NormalizeIntensityd(keys=\"img\", nonzero=True, channel_wise=True),\n",
        "  # augment data to be invariant to intensity shift or scale\n",
        "  mt.RandScaleIntensityd(keys=\"img\", factors=0.1, prob=0.1),\n",
        "  mt.RandShiftIntensityd(keys=\"img\", offsets=0.1, prob=0.1),\n",
        "  # convert to tensor & move to device\n",
        "  mt.ToTensorD(keys=KEYS, device=device)\n",
        "])\n",
        "\n",
        "xform_val = mt.Compose([\n",
        "  # load images\n",
        "  mt.LoadImageD(KEYS),\n",
        "  # make channel the first dimension / add channel dimension if necessary\n",
        "  mt.EnsureChannelFirstD(KEYS),\n",
        "  # fix meta\n",
        "  mt.LambdaD(KEYS, fix_meta),\n",
        "  # print data to ensure fix\n",
        "  # mt.LambdaD(KEYS, print_data),\n",
        "  # make sure tensor type\n",
        "  mt.EnsureTypeD(keys=KEYS),\n",
        "  # make sure all have same orientation (axcode)\n",
        "  mt.Orientationd(keys=KEYS, axcodes=\"RAS\"),\n",
        "  mt.Spacingd(\n",
        "      keys=KEYS,\n",
        "      pixdim=(1.0, 1.0, 1.0),\n",
        "      mode=(\"bilinear\", \"nearest\"),\n",
        "  ),\n",
        "  # normalize intensity\n",
        "  mt.NormalizeIntensityd(keys=\"img\", nonzero=True, channel_wise=True),\n",
        "  # convert to tensor & move to device\n",
        "  mt.ToTensorD(keys=KEYS, device=device)\n",
        "])"
      ],
      "metadata": {
        "id": "XpZnDnTiAWZP"
      },
      "id": "XpZnDnTiAWZP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use PersistentDataset so deterministic preprocessing operations aren't repeated\n",
        "# slow initialization, fast retrieval\n",
        "# cache stored in disk not memory\n",
        "class MRIDataset(ABC, PersistentDataset):\n",
        "    \"\"\"\n",
        "    Base class to generate cross validation datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data,\n",
        "        transform,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        data = self._split_datalist(datalist=data)\n",
        "        super().__init__(data, transform, **kwargs)\n",
        "\n",
        "    @abstractmethod\n",
        "    def _split_datalist(self, datalist):\n",
        "        raise NotImplementedError(f\"Subclass {self.__class__.__name__} must implement this method.\")"
      ],
      "metadata": {
        "id": "_9MfS7xPLSgl"
      },
      "id": "_9MfS7xPLSgl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k-fold cross validation\n",
        "num = 5\n",
        "folds = list(range(num))\n",
        "\n",
        "cache_dir = './cache_dir'\n",
        "\n",
        "cvdataset = CrossValidation(\n",
        "    dataset_cls=MRIDataset,\n",
        "    data=data_dicts[:10], # subset data for Colab\n",
        "    nfolds=num,\n",
        "    transform=xform_train,\n",
        "    cache_dir=cache_dir\n",
        ")"
      ],
      "metadata": {
        "id": "qYPLBTXwLzwQ"
      },
      "id": "qYPLBTXwLzwQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clear cache\n",
        "for c in glob(os.path.join(cache_dir, '*')):\n",
        "  os.remove(c)"
      ],
      "metadata": {
        "id": "hrEmxiH9ULRP"
      },
      "id": "hrEmxiH9ULRP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_workers=0\n",
        "batch_size=1\n",
        "\n",
        "# get datasets\n",
        "train_dss = [cvdataset.get_dataset(folds=folds[0:i] + folds[(i + 1) :]) for i in folds]\n",
        "val_dss = [cvdataset.get_dataset(folds=i, transform=xform_val) for i in folds]\n",
        "\n",
        "# get loaders & set batch size, number of workers, shuffle\n",
        "train_loaders = [DataLoader(train_dss[i], batch_size=batch_size, shuffle=True, num_workers=num_workers) for i in folds]\n",
        "val_loaders = [DataLoader(val_dss[i], batch_size=batch_size, num_workers=num_workers) for i in folds]"
      ],
      "metadata": {
        "id": "VIKbmsCjMhC0"
      },
      "id": "VIKbmsCjMhC0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Data"
      ],
      "metadata": {
        "id": "WpXvqFmWDnOs"
      },
      "id": "WpXvqFmWDnOs"
    },
    {
      "cell_type": "code",
      "source": [
        "ds_idx = 0\n",
        "subj_idx = 0\n",
        "\n",
        "data = train_dss[ds_idx][subj_idx]\n",
        "slice_id = np.argmax(data['seg'][0].sum(axis=[0,1])) # slice with most metastases\n",
        "\n",
        "# visualize a slice from each image modality with segmentation overlay\n",
        "print(f\"subject: {data['img'].meta['filename_or_obj']}\")\n",
        "print(f\"image shape: {data['img'].shape}\")\n",
        "print(f\"segment shape: {data['seg'].shape}\")\n",
        "plt.figure(\"image\", (24, 6))\n",
        "for i, img_type in enumerate(IMG_TYPES):\n",
        "    plt.subplot(1, len(IMG_TYPES), i + 1)\n",
        "    plt.title(f\"image channel {img_type}\")\n",
        "    plt.imshow(data['img'][IMG_TYPES[img_type], :, :, slice_id].detach().cpu(),  cmap=\"gray\")\n",
        "    plt.imshow(data['seg'][0, :, :, slice_id].detach().cpu(), cmap='jet', alpha=0.2) # interpolation='none'\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MpophQYg7raU"
      },
      "id": "MpophQYg7raU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Model"
      ],
      "metadata": {
        "id": "QaV_bKNv52qq"
      },
      "id": "QaV_bKNv52qq"
    },
    {
      "cell_type": "code",
      "source": [
        "net = monai.networks.nets.UNet(\n",
        "    # 3D\n",
        "    spatial_dims=3,\n",
        "    # 4 modalities\n",
        "    in_channels=4,\n",
        "    # 1 channel for output\n",
        "    out_channels=1,\n",
        "    # layers\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    kernel_size=3,\n",
        "    up_kernel_size=3,\n",
        "    num_res_units=2,\n",
        "    act='PRELU',\n",
        "    norm=monai.networks.layers.Norm.BATCH,\n",
        "    dropout=0,\n",
        "    bias=True,\n",
        "    adn_ordering='NDA'\n",
        ").to(device)\n",
        "\n",
        "lr = 1e-2\n",
        "loss = monai.losses.DiceLoss(sigmoid=True)\n",
        "opt = torch.optim.Adam(net.parameters(), lr)"
      ],
      "metadata": {
        "id": "d1L8hUms55j7"
      },
      "id": "d1L8hUms55j7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Bmq4vd7M6AlY"
      },
      "id": "Bmq4vd7M6AlY"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jW4gBZkF6BtE"
      },
      "id": "jW4gBZkF6BtE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-Processing"
      ],
      "metadata": {
        "id": "7PdeoOhdV2Lw"
      },
      "id": "7PdeoOhdV2Lw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete cache\n",
        "import shutil\n",
        "shutil.rmtree(cache_dir)"
      ],
      "metadata": {
        "id": "MJIXa03QV1vJ"
      },
      "id": "MJIXa03QV1vJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwK7IQ2EWRyn"
      },
      "id": "nwK7IQ2EWRyn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}